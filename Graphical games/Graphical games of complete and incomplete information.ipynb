{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4336c2ba-cbff-4d49-8df5-9f2515879888",
   "metadata": {},
   "source": [
    "# Graphical games of complete and incomplete information\n",
    "\n",
    "Author: Muhammed Jabir Thayyil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cad8fc-8e53-49b9-b7f3-38e16f626bdd",
   "metadata": {},
   "source": [
    "### Notations\n",
    "- $a_i$: player $i$'s action\n",
    "- $G$: an undirected graph where vertices are all player $i \\in [n]$ .\n",
    "- $N(i)$: neighborhood of player $i$. i.e., player $i$ and every player $j \\in N(i)$ forms edge $(i,j)$ in $G$. Also player $i$ is included in $N(i)$.\n",
    "- $\\vec{a}^{i}$: joint action of players in $N(i)$\n",
    "- $M_i$: payoff matrix of player $i$\n",
    "- $\\mathbf{E}_{\\vec{a} \\sim P}\\left[M_{i}(\\vec{a})\\right]$: expected payoff for correlated strategy $P$ (probability distribution over joint actions).\n",
    "    - In a graph game expected payoff can be: $$\\mathbf{E}_{\\vec{a}^i \\sim P(\\vec{a}^{i})}\\left[M_{i}(\\vec{a}^i)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1b460-b8e1-4345-a780-a0bb0ac6bb98",
   "metadata": {},
   "source": [
    "## Graphical Game\n",
    "A graphical game is a pair $(G, \\mathcal{M})$, where $G$ is an undirected graph over the vertices $\\{1, \\ldots, n\\}$, and $\\mathcal{M}$ is a set of $n$ local game matrices. For any joint action $\\vec{a}$, the local game matrix $M_{i} \\in \\mathcal{M}$ specifies the payoff $M_{i}\\left(\\vec{a}^{i}\\right)$ for player $i$, which depends only on the actions taken by the players in $N(i)$.\n",
    "\n",
    "- The game is in normal form if the graph is complete.\n",
    "\n",
    "- In a graphical game we don't have to consider all $CE$ distributions due to whats below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78881470-08a3-48b3-ad46-423c561bb8ac",
   "metadata": {},
   "source": [
    "##  Expected Payoff and Local Neighborhood Equivalence\n",
    "\n",
    "Two joint probablity distribution $P$ and $Q$ over joint actions are Expected payoff equivalent (EPE) or Local neighborhood equivalent (LNE) according the following table for all player $i$:\n",
    "\n",
    "|$P \\equiv_{\\mathrm{EP}} Q \\quad$ (EPE)                                        | $P \\equiv_{\\mathrm{LN}} Q \\quad$  (LNE)                                       |\n",
    "|--------------------------------------------|--------------------------------------------|\n",
    "|Expected payoffs are same| The marginal distribution over $N(i)$ are same|\n",
    "|$$\\mathbf{E}_{\\vec{a} \\sim P}\\left[M_{i}(\\vec{a})\\right]=\\mathbf{E}_{\\vec{a} \\sim Q}\\left[M_{i}(\\vec{a})\\right] \\quad \\quad\\quad\\quad$$| $$\n",
    "P\\left(\\vec{a}^{i}\\right)=Q\\left(\\vec{a}^{i}\\right)\n",
    "$$|\n",
    "|$P \\equiv_{\\mathrm{LN}} Q \\implies P \\equiv_{\\mathrm{EP}} Q \\quad$| If $P$ is CE then $Q$ is CE|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8ea51-f8ef-4c73-a4b5-0782591eec58",
   "metadata": {},
   "source": [
    "**Lemma: For all graphs $G$, for all joint distributions $P$ and $Q$ on actions, and for all graphical games with graph $G$, if $P \\equiv_{L N} Q$ then $P \\equiv_{E P} Q$. Furthermore, for any graph $G$ and joint distributions $P$ and $Q$, there exist payoff matrices $\\mathcal{M}$ such that for the graphical game $(G, \\mathcal{M})$, if $P \\neq_{L N} Q$ then $P \\neq_{E P} Q$.**\n",
    "\n",
    "*Proof: The first statement follows from the observation that the expected payoff to player $i$ depends only on the marginal distribution of actions in $N(i)$. To prove the second statement, if $P \\neq_{\\mathrm{LN}} Q$, then there must exist a player $i$ and a joint action $\\vec{a}^{i}$ for its local neighborhood which has a different probability under $P$ and $Q$. Simply set $M_{i}\\left(\\vec{a}^{i}\\right)=1$ and $M_{i}=0$ elsewhere. Then $i$ has a different payoff under $P$ and $Q$, and so $P\\neq_{\\mathrm{EP}} Q$.*\n",
    "\n",
    "**Lemma: For any graphical game $(G, \\mathcal{M})$, if $P$ is a $C E$ for $(G, \\mathcal{M})$ and $P \\equiv_{L N} Q$ then $Q$ is a CE for $(G, \\mathcal{M})$.**\n",
    "\n",
    "Proof: *The lemma follows by noting that the CE expectation equations are dependent only upon the marginal distributions of local neighborhoods, which are preserved in $Q$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704d732-9e58-4c14-80f9-4ee38dd6efd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1614bba-653b-40e8-b6f9-5c58eae5aec5",
   "metadata": {},
   "source": [
    "##  Correlated Equilibria and Markov Nets\n",
    "\n",
    "### Markov network\n",
    "A local Markov network is a pair $M \\equiv(G, \\Psi)$, where\n",
    "- $G$ is an undirected graph on vertices $\\{1, \\ldots, n\\}$\n",
    "- $\\Psi$ is a set of potential functions, one for each local neighborhood $N(i)$, mapping binary assignments of values of $N(i)$ to the range $[0, \\infty)$ :\n",
    "$$\n",
    "\\Psi \\equiv\\left\\{\\psi_{i}: i=1, \\ldots, n ; \\psi_{i}:\\left\\{\\vec{a}^{i}\\right\\} \\rightarrow[0, \\infty)\\right\\}\n",
    "$$\n",
    "where $\\left\\{\\vec{a}^{i}\\right\\}$ is the set of all $2^{|N(i)|}$ settings to $N(i)$.\n",
    "\n",
    "#### Probablity distribution\n",
    "A local Markov network $M$ defines a probability distribution $P_{M}$ as follows. For any binary assignment $\\vec{a}$ to the vertices, we define\n",
    "$$\n",
    "P_{M}(\\vec{a}) \\equiv \\frac{1}{Z}\\left(\\prod_{i=1}^{n} \\psi_{i}\\left(\\vec{a}^{i}\\right)\\right)\n",
    "$$\n",
    "where $Z=\\sum_{\\vec{a}} \\prod_{i=1}^{n} \\psi_{i}\\left(\\vec{a}^{i}\\right)>0$ is the normalization factor.\n",
    "\n",
    "### To note:\n",
    "- any joint distribution can be represented as a local Markov network on a sufficiently dense graph: \n",
    "    - if we let G be the complete graph then we simply have a single potential function over the entire joint action space $\\vec{a}$.\n",
    "- if d is the size of the maximal neighborhood in G, then the representation size of a distribution in this network is $O(n2^d)$, a considerable savings over a tabular representation if $d << n$.\n",
    "\n",
    "##### local markov networks are a special case of markove network\n",
    "- the potential function defined on Markov networks range over *maximal cliques*, and not local neighborhood.\n",
    "- Another approach:\n",
    "    - transform $G$ to $G^{\\prime}$ so that local $N(i)$ in $G^{\\prime}$ forms maximal clique, and use standard markov network over $G^{\\prime}$.\n",
    "        - disadventage: result in exponential blow up when resulting maximal clique is much larger than orginal $N(i)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabc96a-4057-4302-890f-fa8616da3beb",
   "metadata": {},
   "source": [
    "## Representing correlated strategy as markov network\n",
    "\n",
    "**Lemma: For all graphs $G$, and for all joint distributions $P$ over joint actions, there exists a distribution $Q$ that is representable as a local Markov network with graph $G$ such that $Q \\equiv_{L N} P$ with respect to $G$.**\n",
    "\n",
    "*Proof:* \n",
    "- our objective:\n",
    "    - to find a $Q \\equiv_{L N} P$ and that we can write that $Q$ as: $$\n",
    "Q(\\vec{a})= \\frac{1}{Z} \\prod_{i=1}^{n} \\psi_{i} \\left(\\vec{a}^{i}\\right)\n",
    "$$\n",
    "- Claim: the maximal entropy $Q^{\\star}$ subjected to $Q^{\\star} \\equiv_{L N} P$ should do the job.\n",
    "\n",
    "- so we the optimization problem:$$\n",
    "Q^{*}=\\operatorname{argmax}_{Q} H(Q) \\equiv \\operatorname{argmax}_{Q} \\sum_{\\vec{a}} Q(\\vec{a}) \\log (1 / Q(\\vec{a}))\n",
    "$$\n",
    "    - subjected to:\n",
    "         1. $Q\\left(\\vec{a}^{i}\\right)=P\\left(\\vec{a}^{i}\\right)$, for all $i, \\vec{a}^{i}$.\n",
    "         2. $Q$ is a proper probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e89650-560f-4897-ba19-27c3ff47a8cc",
   "metadata": {},
   "source": [
    "- Using lagrangian multiplyers $$\n",
    "\\begin{aligned}\n",
    "Q^{*}=& \\operatorname{argmax}_{Q, \\vec{\\lambda}, \\beta}\\{L(Q, \\vec{\\lambda}, \\beta)\\} \\\\\n",
    "\\equiv & \\operatorname{argmax}_{Q, \\vec{\\lambda}, \\beta}\\left\\{H(Q)+\\sum_{i \\in[n]} \\sum_{\\vec{a}^{i}} \\lambda_{i, \\vec{a}}{ }^{i}\\left(Q\\left(\\vec{a}^{i}\\right)-P\\left(\\vec{a}^{i}\\right)\\right)\\right.&\\left.+\\beta\\left(\\sum_{\\vec{a}} Q(\\vec{a})-1\\right)\\right\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- $Q^{*}$ is such that $\\partial L /\\left.\\partial Q(\\vec{a})\\right|_{Q=Q^{*}}=0 \\quad \\forall \\vec{a}$ with $P(\\vec{a})>0$ \n",
    "\n",
    "- Solving it yeilds,\n",
    "$$\n",
    "Q_{\\vec{\\lambda}}^{*}(\\vec{a})=\\left(1 / Z_{\\vec{\\lambda}}\\right) \\prod_{v=1}^{n} I\\left[P\\left(\\vec{a}^{i}\\right) \\neq 0\\right] \\exp \\left(\\lambda_{i, \\vec{a}^{i}}\\right),\n",
    "$$\n",
    "    - where $I\\left[P\\left(\\vec{a}^{i}\\right) \\neq 0\\right]$ is an indicator function that evaluates to 1 iff $P\\left(\\vec{a}^{i}\\right) \\neq 0$.\n",
    "    \n",
    "    - The subscript $\\vec{\\lambda}$ is used on $Q_{\\vec{\\lambda}}^{*}$ and $Z_{\\vec{\\lambda}}$ to explicitly denote that they are parameterized by the Lagrange multipliers.\n",
    "\n",
    "- Let the dual function be $F (\\vec{\\lambda}) = L\\left(Q_{\\vec{\\lambda}}^{*}(\\vec{a}), \\vec{\\lambda}, 0\\right)$: \n",
    "    - let $\\vec{\\lambda}^{*}$ maximize this function\n",
    "    \n",
    "    - for all $i$ and $\\vec{a}^{i}$ such that $P\\left(\\vec{a}^{i}\\right)=0$, set $\\lambda_{i, \\vec{a}^i}^{*}=0$. \n",
    "    \n",
    "- For all $i, \\vec{a}^{i}$, define the functions: \n",
    "$$\\psi_{i}^{*}\\left(\\vec{a}^{i}\\right) \\equiv I\\left[P\\left(\\vec{a}^{i}\\right) \\neq 0\\right] \\exp \\left(\\lambda_{i, \\vec{a}^i }^{*}\\right)$$ \n",
    "    \n",
    "- Hence, the maximum entropy distribution $Q^{*}$, for all $\\vec{a}$,\n",
    "$$\n",
    "Q_{\\lambda^{*}}^{*}(\\vec{a})=\\left(1 / Z_{\\vec{\\lambda}^{*}}\\right) \\prod_{i=1}^{n} \\psi_{i}^{*}\\left(\\vec{a}^{i}\\right)\n",
    "$$\n",
    "\n",
    "    - Dangerous question: any sort of relation or some way to connect the thing above to born's rule? \n",
    "\n",
    "\n",
    "- and that completes the proof.\n",
    "\n",
    "Thus correlated equilibria of a graphical game $(G, \\mathcal{M})$, up to payoff equivalence, can be represented with a local Markov network $(G, \\Psi)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73c684-465b-424b-a1b0-c81f7be61af4",
   "metadata": {},
   "source": [
    "## The final theorem\n",
    "*Theorem: For all graphical games $(G, \\mathcal{M})$, and for any correlated equilibrium $P$ of $(G, \\mathcal{M})$, there exists a distribution $Q$ such that*\n",
    "1. $Q$ is also correlated equilibrium for $(G, \\mathcal{M})$;\n",
    "2. $Q$ gives all players the same expected payoffs as $P: Q \\equiv_{E P} P$; and\n",
    "3. $Q$ can be represented as a local Markov network with graph $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516c912-5539-4ab2-986e-174eaec855ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83909ed8-d89b-4a0c-8b1a-98722f2f674f",
   "metadata": {},
   "source": [
    "## Transforming this thing to game of incomplete information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a0d1d-953b-44c6-8d2b-9316a8f20750",
   "metadata": {},
   "source": [
    "- So every vertices looks at their type drawn from an external join distribution while executing their action\n",
    "- The correlated strategy becomes conditional\n",
    "\n",
    "So:\n",
    "- $M_i(\\vec{a}^i) \\longrightarrow M_i(\\vec{a}^i, \\vec{t}^i)$\n",
    "\n",
    "    - if $M_i(\\vec{a}^i) \\longrightarrow M_i(\\vec{a}^i, \\vec{t})$, then then that another interesting class of bayesian graph games!\n",
    "        \n",
    "        - for such a definintion, we gotta come up with another graph to capture \"type dependecies\"!\n",
    "\n",
    "- $P(\\vec{a}) \\longrightarrow P(\\vec{s} \\mid \\vec{r})$\n",
    "\n",
    "- $P(\\vec{a}^i) \\longrightarrow P^{(-\\vec{r}^i)}(\\vec{s}^i \\mid \\vec{r}^i)$:\n",
    "    \n",
    "    - if $P$ is non-signalling, then $P^{(-\\vec{r}^i)}(\\vec{s}^i \\mid \\vec{r}^i) = P^{(-\\vec{r^{\\prime}}^i)}(\\vec{s}^i \\mid \\vec{r}^i) \\quad \\forall -\\vec{r}^i, -\\vec{r^{\\prime}}^i$\n",
    "    \n",
    "        - Then we can neglet the lable $(-\\vec{r}^i)$\n",
    "        \n",
    "        - so : $P(\\vec{a}^i) \\longrightarrow P(\\vec{s}^i \\mid \\vec{r}^i)$\n",
    "        \n",
    "        - However the above definition doesn't mean $P$ is completely non-signalling. It only tells players outside neighbourhood $N(i)$ cannot signal their inputs to those players inside $N(i)$. But t can be the case $P$ is signalling for player inside $N(i)$. We can term such case as \"interior signalling\" or \"interior non-signalling\". Or in other words, the marginal $P(\\vec{s}^i \\mid \\vec{r}^i)$ can be signalling or non-signalling. \n",
    "            \n",
    "            - Weather $P$ is \"exterior signalling/non-signalling\" doesn't matter to us since, $-\\vec(r)^i$ is a useless information to players in $N(i)$ for this particular class of bayesian graph games we are currently dealing with. \n",
    "        \n",
    "     - if $P$ is overall signalling then we cant neglet the label $(-\\vec{r}^i)$ and we'll have to deal with all those different conditional probaility distributions\n",
    "     \n",
    "         - luckily for our interest on quantum advice, the POVM strategies are local and non-signalling. So we dont have to worry about it.\n",
    "         \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcd360-401b-4b41-9d00-1a3b678276b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8bf9a7-95df-4fe9-8251-29244fc58637",
   "metadata": {},
   "source": [
    "# General bayesian graphical games\n",
    "\n",
    "### my definition:\n",
    "\n",
    "A graphical game is a tuple $(\\mathcal{A}, \\mathcal{T}, \\mathcal{M})$, where $\\mathcal{A}, \\mathcal{T}$ are undirected graphs over the vertices $\\{1, \\ldots, n\\}$ sepecified for Action dependecies and Type dependecies respectively, and $\\mathcal{M}$ is a set of $n$ local game matrices. For any joint action $\\vec{a}$, the local game matrix $M_{i} \\in \\mathcal{M}$ specifies the payoff $M_{i}\\left(\\vec{a}^{i}, \\vec{t}^{i} \\right)$ for player $i$, which depends only on the actions taken by the players in neghbourhood $N_{\\mathcal{A}}(i)$ of $\\mathcal{A}$ and types of the players in neghbourhood $N_{\\mathcal{T}}(i)$ of $\\mathcal{T}$.\n",
    "\n",
    "- This reproduces the above game we talked about if $\\mathcal{A} = \\mathcal{T}$.\n",
    "\n",
    "- While considering non-signalling strategies, only input information of players within $N_{\\mathcal{T}}(i)$ matters for player $i$. As for those input information of players outside $N_{\\mathcal{T}}(i)$ is useless for player $i$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8f577-9b39-46bb-a296-2cd047f812a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
